{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef359dca-3cbc-4051-b38b-1b8d489decfd",
   "metadata": {},
   "source": [
    "# This script is to download CMIP6 data using intake-esm library\n",
    "\n",
    "Read more from link\n",
    "\n",
    "https://intake-esm.readthedocs.io/en/stable/tutorials/loading-cmip6-data.html\n",
    "\n",
    "How to use intake to download GCM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63679b9-8aa5-40ec-af02-1d86452529ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import chunk_util\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862884b6-92db-4a09-b358-a9f4fb2afae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information of all CMIP6 files that one can download from intake esm data store\n",
    "url = \"https://raw.githubusercontent.com/NCAR/intake-esm-datastore/master/catalogs/pangeo-cmip6.json\"\n",
    "url = \"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798a33-6051-4272-9740-1bd26304c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort(l: Iterable[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Sort names like r1i1p1f1, r1i2p1f1 in a natural (numeric) order.\n",
    "    - r1: Realization (initial condition run),\n",
    "    - i1: Initialization method,\n",
    "    - p1: Physical parameters,\n",
    "    - f1: External forcings.\n",
    "\n",
    "    Numeric order means that r1i1p1f1 < r2i1p1f1 < r11i1p1f1.\n",
    "\n",
    "    :param l: list of names to be sorted\n",
    "    \"\"\"\n",
    "\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split(\"([0-9]+)\", key)]\n",
    "    return sorted(l, key=alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93778d6c-7b0a-4806-b84c-3b3b39c4fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(\n",
    "    catalog_url: str, sid: str, exp: str, var: str, start_year: int, end_year: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Download files from the CMIP6 data store\n",
    "\n",
    "    :param catalog_url: intake esm data store\n",
    "    :param sid: source_id\n",
    "    :param exp: experiment_id\n",
    "    :param var: variable_id\n",
    "    \"\"\"\n",
    "\n",
    "    catalog = intake.open_esm_datastore(catalog_url)\n",
    "    models = catalog.search(\n",
    "        experiment_id=exp,\n",
    "        table_id=\"Amon\",\n",
    "        variable_id=var,\n",
    "        source_id=sid,\n",
    "    )\n",
    "    # then one might get several files with the same conditions\n",
    "    # r1: Realization (initial condition run)\n",
    "    # i1: Initialization method\n",
    "    # p1: Physical parameters\n",
    "    # f1: External forcings\n",
    "\n",
    "    # if no files exist then print out error\n",
    "    if len(models.df) == 0:\n",
    "        print(\"*** No data found for\", var, exp, sid)\n",
    "        return False\n",
    "\n",
    "    member_ids = natural_sort(models.df.member_id.values)\n",
    "\n",
    "    # get the first one only then seach again\n",
    "    first_member_id = member_ids[0]\n",
    "    first_member = catalog.search(\n",
    "        experiment_id=exp,\n",
    "        table_id=\"Amon\",\n",
    "        variable_id=var,\n",
    "        source_id=sid,\n",
    "        member_id=first_member_id,\n",
    "    )\n",
    "\n",
    "    # if no files exist then print out error\n",
    "    if len(first_member.df) == 0:\n",
    "        print(\n",
    "            \"*** This is impossible, there must be data for\",\n",
    "            var,\n",
    "            exp,\n",
    "            sid,\n",
    "            member_ids[0],\n",
    "        )\n",
    "        return False\n",
    "\n",
    "    odir = Path(\"Download\") / sid / exp\n",
    "    odir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def output_file_name(key):\n",
    "        return odir / f\"{var}_{key}_{first_member_id}_{start_year}_{end_year}.nc\"\n",
    "\n",
    "    try:\n",
    "        # If all output files exist, skip\n",
    "        if all((output_file_name(key)).exists() for key in first_member.keys()):\n",
    "            return True\n",
    "\n",
    "        datasets: dict[str, xr.Dataset] = first_member.to_dataset_dict(\n",
    "            xarray_open_kwargs={\"consolidated\": True}, progressbar=False\n",
    "        )\n",
    "\n",
    "        for key, ds in datasets.items():\n",
    "            # Must use isin because some dataset has time variable not monotonically increasing\n",
    "            year_data = ds.sel(\n",
    "                time=ds.time.dt.year.isin(np.arange(start_year, end_year + 1))\n",
    "            )\n",
    "\n",
    "            years = np.unique(year_data.time.dt.year.values)\n",
    "\n",
    "            if len(years) == 0:\n",
    "                print(\n",
    "                    f\"{sid}, {exp}, {var}, requested {start_year}-{end_year} data but no data found\"\n",
    "                )\n",
    "                return False\n",
    "\n",
    "            if years[0] != start_year or years[-1] != end_year:\n",
    "                print(\n",
    "                    f\"{sid}, {exp}, {var}, requested {start_year}-{end_year} data \"\n",
    "                    f\"but only {years[0]}-{years[-1]} data found\"\n",
    "                )\n",
    "                return False\n",
    "\n",
    "            month_mean = year_data.groupby(\"time.month\").mean(\"time\").squeeze(drop=True)\n",
    "\n",
    "            ofile = output_file_name(key)\n",
    "            tmp_ofile = ofile.with_suffix(\".tmp.nc\")\n",
    "\n",
    "            # Compression\n",
    "            encoding = {\n",
    "                var_name: {\n",
    "                    \"zlib\": True,\n",
    "                    \"complevel\": 1,\n",
    "                    \"chunksizes\": chunk_util.chunk_shape_nD(\n",
    "                        data.shape, chunkSize=64 * 2**10\n",
    "                    ),\n",
    "                }\n",
    "                for var_name, data in month_mean.data_vars.items()\n",
    "            }\n",
    "\n",
    "            # Save to temporary file first, and then rename to output file to\n",
    "            # avoid regarding corrupted file due to sudden termination as\n",
    "            # complete file.\n",
    "            month_mean.to_netcdf(\n",
    "                tmp_ofile, format=\"NETCDF4_CLASSIC\", engine=\"netcdf4\", encoding=encoding\n",
    "            )\n",
    "            tmp_ofile.rename(ofile)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"*** Couldn't download\", var, exp, sid, e)\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddace358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_files(url, \"EC-Earth3\", \"historical\", \"tas\", 1995, 2014)\n",
    "download_files(url, \"MPI-ESM1-2-HR\", \"historical\", \"tas\", 1995, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "    source_ids: list[str],\n",
    "    experiments: list[str],\n",
    "    variables: list[str],\n",
    "    start_year: int,\n",
    "    end_year: int,\n",
    "):\n",
    "    status = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = []\n",
    "        status = []\n",
    "        for sid in source_ids:\n",
    "            for exp in experiments:\n",
    "                for var in variables:\n",
    "                    future = executor.submit(\n",
    "                        download_files, url, sid, exp, var, start_year, end_year\n",
    "                    )\n",
    "                    futures.append(future)\n",
    "                    status.append(\n",
    "                        {\n",
    "                            \"source_id\": sid,\n",
    "                            \"experiment\": exp,\n",
    "                            \"variable\": var,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        for future, stat in tqdm(zip(futures, status), total=len(futures)):\n",
    "            try:\n",
    "                success = future.result()\n",
    "            except Exception as e:\n",
    "                success = False\n",
    "                print(\"*** Error:\", e)\n",
    "\n",
    "            stat[\"success\"] = success\n",
    "\n",
    "    return pd.DataFrame(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f33a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = [\n",
    "    \"EC-Earth3\",\n",
    "    \"MIROC6\",\n",
    "    \"MRI-ESM2-0\",\n",
    "    \"ACCESS-CM2\",\n",
    "    \"IPSL-CM6A-LR\",\n",
    "    \"MPI-ESM1-2-HR\",\n",
    "]\n",
    "experiments = [\"ssp585\"]\n",
    "variables = [\"tas\", \"ta\", \"ua\", \"va\", \"hur\", \"zg\", \"ts\"]\n",
    "\n",
    "historical_status = download_data(source_ids, [\"historical\"], variables, 1995, 2014)\n",
    "ssp_status = download_data(source_ids, experiments, variables, 2045, 2064)\n",
    "\n",
    "download_status = pd.concat([historical_status, ssp_status], ignore_index=True)\n",
    "print(f\"Successfully downloaded {download_status['success'].sum()} files\")\n",
    "\n",
    "failed_download = download_status.query(\"~success\")\n",
    "if not failed_download.empty:\n",
    "    print(\"Couldn't download the following files\")\n",
    "    print(failed_download)\n",
    "else:\n",
    "    print(\"No failed download\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
